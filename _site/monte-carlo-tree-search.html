<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <link rel="preload" href="min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <link rel="icon" href="favicon.svg">
    
    <link defer rel="stylesheet" href="min.css">
    <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">
    
    <!-- Katex -->
    <script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
    <script>document.addEventListener("DOMContentLoaded", function () {
      var mathElements = document.getElementsByClassName("math");
      var macros = [];
      for (var i = 0; i < mathElements.length; i++) {
        var texText = mathElements[i].firstChild;
        if (mathElements[i].tagName == "SPAN") {
        katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }}});
    </script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css" />
    
    <meta name="date" content=''>
    <title>Monte Carlo Tree Search</title>
  </head>
  <body>
    <h1><a href="/"a>← Monte Carlo Tree Search</a></h1>
    <p class="date">Dec 23, 2023 &ndash; Dec 24, 2023</p>
    <main>
      <p><em>Note: I’m pretty new to RL, so please let me know if
      there’s anything incorrect here! Also still planning on adding
      images and cleaning up a bunch of my explanations</em></p>
      <p>I’ve recently been very enamored by MCTS since at it’s core, as
      it is a prime example of the <a
      href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">Bitter
      Lesson</a> from <a href="ai">AI</a>. In broad strokes, MCTS is a
      way to figure out how to play games optimally <em>without</em> any
      notion of what is good. Traditionally in something like a <a
      href="https://en.wikipedia.org/wiki/Minimax">minimax</a>, you have
      to build in human heuristics of what’s good in order to limit your
      search space, but MCTS is pure search. How “good” a position is,
      is just what percentage of the time you win from a given state.
      But how do you estimate that with no knowledge of the game? Once
      you get to a state: you simply just play random moves until you
      get to end. Do this enough times, and your estimation of a state
      will approach truth.</p>
      <blockquote>
      <p>This isn’t quite how <a
      href="https://en.wikipedia.org/wiki/AlphaZero">AlphaZero</a> works
      since it replaces the rollouts with neural network evaluations,
      but this also isn’t a built in human heuristic. It’s still pure
      <strong>search</strong> and <strong>learning</strong>.</p>
      </blockquote>
      <h2 id="the-algorithm">The algorithm</h2>
      <p>MCTS proceeds in four steps: selection, expansion, rollout,
      backpropogation.</p>
      <p>In <strong>selection</strong>, you recursively select a state
      to go to until you’ve hit a leaf node. After that, you
      <strong>expand</strong> out all possible states that you can
      reach. Since we don’t have any heuristics for how best to play the
      game (at least in Vanilla MCTS), we now <strong>rollout</strong>
      from that position which means to play random moves until one side
      wins. After you get a result of who won, you can
      <strong>backpropagate</strong> that “reward” through each
      node.</p>
      <p>The general algorithm will look something like this:</p>
      <div class="sourceCode" id="cb1"><pre
      class="sourceCode py"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="bu">iter</span>(<span class="va">self</span>, node):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Play out one game from root node&quot;&quot;&quot;</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    path <span class="op">=</span> <span class="va">self</span>._select(node)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    leaf <span class="op">=</span> path[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>._expand(leaf)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    reward <span class="op">=</span> <span class="va">self</span>._rollout(leaf)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>._backpropogate(path, reward)</span></code></pre></div>
      <p>But now let’s break it up into parts.</p>
      <h3 id="selection">Selection</h3>
      <div class="sourceCode" id="cb2"><pre
      class="sourceCode py"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _select(node):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Returns a path of nodes to reach a leaf node&quot;&quot;&quot;</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    path <span class="op">=</span> []</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        path.append(node)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> node <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.children <span class="kw">or</span> node.is_terminal:</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> path     <span class="co"># This means we haven&#39;t explored this node or it&#39;s the end</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        unexplored <span class="op">=</span> <span class="va">self</span>.children[node] <span class="op">-</span> <span class="va">self</span>.children.keys()</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If there are unexplored children states, go to them!</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> unexplored:</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>            n <span class="op">=</span> unexplored.pop()</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>            path.append(n)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> path</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If all you&#39;re children states have been explored, then choose one &quot;optimally&quot;</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        node <span class="op">=</span> <span class="va">self</span>._uct_select(node)</span></code></pre></div>
      <p>As you’re building the tree, there’s this tension between
      exploration and exploitation. Do you want to go explore the states
      that haven’t been visited, or do you want to go further in the
      “best” states? <a
      href="https://www.chessprogramming.org/UCT">Upper Confidence Bound
      for Trees (UCT)</a> is one way to try and balance those.</p>
      <div class="sourceCode" id="cb3"><pre
      class="sourceCode py"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _uct_select(<span class="va">self</span>, node):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    log_N <span class="op">=</span> math.log(<span class="va">self</span>.N[node])</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> uct(c):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.Q[c] <span class="op">/</span> <span class="va">self</span>.N[c] </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>             <span class="op">+</span> <span class="va">self</span>.exploration_weight <span class="op">*</span> math.sqrt(</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>                log_N <span class="op">/</span> <span class="va">self</span>.N[c]</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>             )</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">max</span>(<span class="va">self</span>.children[node], key<span class="op">=</span>uct)</span></code></pre></div>
      <p>For each node, we give a score as <span
      class="math inline">\text{UCT}_i = \frac{q_i}{n_i} + c *
      \sqrt{\frac{\ln n}{n_i}}</span></p>
      <ul>
      <li><span class="math inline">q_i</span> is the total we’ve gotten
      at a state over many visits</li>
      <li><span class="math inline">n_i</span> is how many times we’ve
      visited a node</li>
      <li><span class="math inline">c</span> is an exploration term of
      how we want to balance exploitation/exploration</li>
      <li><span class="math inline">n</span> is how many times the
      parent node has been visited</li>
      <li><span class="math inline">n_i</span> is how many times our
      child node has been visited</li>
      </ul>
      <p>Our first term (<span
      class="math inline">\frac{q_i}{n_i}</span>) measures our average
      reward over every time we’ve visited this state. You can think of
      this as our exploitation term. Of course, we don’t just want to
      explore the first state that gives us reward, so our second term
      (<span class="math inline">\sqrt{\frac{\ln n}{n_i}}</span>) is a
      measure of how uncertain we are of our reward estimation. The less
      you’ve visited a node, the more uncertain you should be. We use
      <span class="math inline">\ln n</span> since we want to prioritize
      exploration less over time as our exploitation term becomes more
      accurate.</p>
      <h3 id="expansion">Expansion</h3>
      <div class="sourceCode" id="cb4"><pre
      class="sourceCode py"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _expand(<span class="va">self</span>, node):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> node <span class="kw">in</span> <span class="va">self</span>.children:</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span>  <span class="co"># you already expanded</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.children[node] <span class="op">=</span> node.find_children()</span></code></pre></div>
      <p>Now that we have a leaf node, let’s expand it! This means to
      look at all possible states that we can reach from where we are.
      The exact implementation of how the nodes find children is game
      dependent. If we were playing chess, the
      <code>node.find_children()</code> would give you all the possible
      moves for whichever player is currently taking a turn.</p>
      <h3 id="rollout">Rollout</h3>
      <div class="sourceCode" id="cb5"><pre
      class="sourceCode py"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _rollout(<span class="va">self</span>, node):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    invert_reward <span class="op">=</span> <span class="va">True</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> node.is_terminal():</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>            reward <span class="op">=</span> node.reward()</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="dv">1</span> <span class="op">-</span> reward <span class="cf">if</span> invert_reward <span class="cf">else</span> reward</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        node <span class="op">=</span> node.find_random_child()</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        invert_reward <span class="op">=</span> <span class="kw">not</span> invert_reward</span></code></pre></div>
      <p>Like we showed before, rolling out is just playing random moves
      until you reach an end state where the game is over. There is one
      key distinction here in that if you’re playing a 2-player game,
      then you’ll have to invert the rewards each time you go up a node.
      If your opponent wins (reward of 1), then you’ve lost (reward
      0).</p>
      <h3 id="backpropagation">Backpropagation</h3>
      <div class="sourceCode" id="cb6"><pre
      class="sourceCode py"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _backpropogate(<span class="va">self</span>, path, reward):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> node <span class="kw">in</span> <span class="bu">reversed</span>(path):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Q[node] <span class="op">+=</span> reward</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.N[node] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        reward <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> reward     <span class="co"># same flipping as rollout</span></span></code></pre></div>
      <p>Now that we have a reward, we need to backpropogate it back to
      the states that led to our leaf node. In this implementation, we
      use a <code>Q</code> and <code>N</code> dictionary that stores the
      reward and times visited for each node.</p>
      <h2 id="yay">Yay!!</h2>
      <p>If you got through this whole thing, then you now have a pretty
      solid understanding of how basic MCTS works! There are a lot of
      things left to learn like how to implement it so that you can
      parallelize the search, better upper confidence bounds (look up
      PUCT), and combining the base algorithm with NNs to reach modern
      state of the art performance. I’ve left a few links below with
      implementations and extensions of what I have here.</p>
      <h2 id="useful-links">Useful links</h2>
      <ul>
      <li><a href="https://jyopari.github.io/MCTS.html">Jyopari</a></li>
      <li><a
      href="https://web.stanford.edu/~surag/posts/alphazero.html">Simple
      Alpha Zero</a></li>
      <li><a
      href="https://gist.github.com/qpwo/c538c6f73727e254fdc7fab81024f6e1">Minimal
      impl. in Python</a></li>
      </ul>
    </main>
    <script src="//instant.page/5.1.1" type="module" integrity="sha384-MWfCL6g1OTGsbSwfuMHc8+8J2u71/LA8dzlIN3ycajckxuZZmF+DNjdm7O6H3PSq"></script>
  </body>
</html>
